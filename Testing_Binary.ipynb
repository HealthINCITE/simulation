{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Testing - Binary.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IyU3LAo8D9Ks",
        "colab_type": "text"
      },
      "source": [
        "# Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5o5sY3dj_Zoy",
        "colab_type": "text"
      },
      "source": [
        "This notebook has four main objectives:\n",
        "\n",
        "1. First we generate synthetic data using the DGen module\n",
        "2. Second we use kmeans to determine optimum number of cadres\n",
        "3. Then we test  results from step 2, using regular Logistic Regression (since the target is binary)\n",
        "4.  Third, we replicate the SCM from the binaryClassification2.py module \n",
        "5. Finally, we also look at how well the classifications perform\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPLueMBF-ffH",
        "colab_type": "code",
        "outputId": "9e7f8c1d-3f0d-455e-cf91-2e621f0ac54e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        }
      },
      "source": [
        "# pull from git repositories\n",
        "!git clone https://github.com/jorje1908/SGMM.git\n",
        "!git clone https://github.com/newalexander/supervised-cadres.git\n",
        "!git clone https://github.com/HealthINCITE/cadre.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'SGMM'...\n",
            "remote: Enumerating objects: 363, done.\u001b[K\n",
            "remote: Counting objects: 100% (363/363), done.\u001b[K\n",
            "remote: Compressing objects: 100% (236/236), done.\u001b[K\n",
            "remote: Total 363 (delta 232), reused 250 (delta 125), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (363/363), 230.93 KiB | 245.00 KiB/s, done.\n",
            "Resolving deltas: 100% (232/232), done.\n",
            "Cloning into 'supervised-cadres'...\n",
            "remote: Enumerating objects: 39, done.\u001b[K\n",
            "remote: Counting objects: 100% (39/39), done.\u001b[K\n",
            "remote: Compressing objects: 100% (39/39), done.\u001b[K\n",
            "remote: Total 431 (delta 25), reused 0 (delta 0), pack-reused 392\u001b[K\n",
            "Receiving objects: 100% (431/431), 321.92 KiB | 440.00 KiB/s, done.\n",
            "Resolving deltas: 100% (250/250), done.\n",
            "Cloning into 'cadre'...\n",
            "remote: Enumerating objects: 215, done.\u001b[K\n",
            "remote: Counting objects: 100% (215/215), done.\u001b[K\n",
            "remote: Compressing objects: 100% (149/149), done.\u001b[K\n",
            "remote: Total 215 (delta 85), reused 142 (delta 35), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (215/215), 1.01 MiB | 439.00 KiB/s, done.\n",
            "Resolving deltas: 100% (85/85), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BkH3Ecb-gRB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from  sklearn.datasets import make_regression\n",
        "import pandas as pd    \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "# imports for data generator module\n",
        "import sys\n",
        "sys.path.append('cadre/cadre/modules/simulation')\n",
        "sys.path.append('cadre/cadre/modules/other')\n",
        "from dgen import DGenerator\n",
        "\n",
        "# imports for SGMM \n",
        "sys.path.append('SGMM/SGMM')\n",
        "sys.path.append('SGMM/metrics')\n",
        "\n",
        "# imports for SCM\n",
        "import sys\n",
        "from scipy.stats import zscore, zmap\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from itertools import product\n",
        "from joblib import Parallel, delayed\n",
        "from multiprocessing import cpu_count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxqzT_eVD2Ct",
        "colab_type": "text"
      },
      "source": [
        "# Generate Cadre and Cadre Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oLbDK2H-gWU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# assign attributes\n",
        "\n",
        "c_samples = 1000   #Number of samples\n",
        "c_features = 10     #Number of features\n",
        "c_informative = 5   #Number of featurs that are informative\n",
        "c_cadres = 5        #Number of cadres\n",
        "c_seed = 101        #Randome seed (for repeatability)\n",
        "c_red = 0           #Number of redundant features (test of multicolinearity impact)\n",
        "c_classep = 4       #Cadre separation (are there large separations among cadres or are they similar)\n",
        "c_flip = 0          #Cadre membership flip.  This will flip the membership of x% of cadres"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNjOkb9JE8Cf",
        "colab_type": "text"
      },
      "source": [
        "Next, we generate features and cadres based on these features. So these are cadre features. This will help us test the classification modules later on"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gl3NgARi-gbA",
        "colab_type": "code",
        "outputId": "04168ec8-c842-47da-ed7b-cdf54839687f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df_cadre = DGenerator.generate_cadres(samples = c_samples, features = c_features, informative = c_informative, cadres = c_cadres, seed = c_seed, redundant = c_red, classep = c_classep, flip = c_flip)\n",
        "df_cadre.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cad0</th>\n",
              "      <th>cad1</th>\n",
              "      <th>cad2</th>\n",
              "      <th>cad3</th>\n",
              "      <th>cad4</th>\n",
              "      <th>cad5</th>\n",
              "      <th>cad6</th>\n",
              "      <th>cad7</th>\n",
              "      <th>cad8</th>\n",
              "      <th>cad9</th>\n",
              "      <th>cadre</th>\n",
              "      <th>index_c</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-4.482410</td>\n",
              "      <td>-4.619843</td>\n",
              "      <td>-0.997349</td>\n",
              "      <td>0.566676</td>\n",
              "      <td>2.126565</td>\n",
              "      <td>1.777562</td>\n",
              "      <td>3.996400</td>\n",
              "      <td>0.529722</td>\n",
              "      <td>5.346935</td>\n",
              "      <td>2.831843</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-4.275286</td>\n",
              "      <td>-2.881474</td>\n",
              "      <td>-2.370080</td>\n",
              "      <td>-0.983635</td>\n",
              "      <td>0.938040</td>\n",
              "      <td>0.678835</td>\n",
              "      <td>3.397562</td>\n",
              "      <td>0.145567</td>\n",
              "      <td>3.981830</td>\n",
              "      <td>3.362928</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.775304</td>\n",
              "      <td>-2.224774</td>\n",
              "      <td>-1.369726</td>\n",
              "      <td>-0.906824</td>\n",
              "      <td>-0.686132</td>\n",
              "      <td>0.601892</td>\n",
              "      <td>4.045526</td>\n",
              "      <td>1.985196</td>\n",
              "      <td>3.116355</td>\n",
              "      <td>-3.835390</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-3.144241</td>\n",
              "      <td>-3.155927</td>\n",
              "      <td>-0.103750</td>\n",
              "      <td>0.712932</td>\n",
              "      <td>1.052544</td>\n",
              "      <td>0.615533</td>\n",
              "      <td>3.637596</td>\n",
              "      <td>-0.801713</td>\n",
              "      <td>2.217286</td>\n",
              "      <td>4.895699</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.543432</td>\n",
              "      <td>-4.854725</td>\n",
              "      <td>1.101187</td>\n",
              "      <td>0.297339</td>\n",
              "      <td>-0.196661</td>\n",
              "      <td>-0.038621</td>\n",
              "      <td>3.212342</td>\n",
              "      <td>1.442216</td>\n",
              "      <td>1.648459</td>\n",
              "      <td>6.916369</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       cad0      cad1      cad2      cad3  ...      cad8      cad9  cadre  index_c\n",
              "0 -4.482410 -4.619843 -0.997349  0.566676  ...  5.346935  2.831843      0        0\n",
              "1 -4.275286 -2.881474 -2.370080 -0.983635  ...  3.981830  3.362928      0        1\n",
              "2  2.775304 -2.224774 -1.369726 -0.906824  ...  3.116355 -3.835390      0        2\n",
              "3 -3.144241 -3.155927 -0.103750  0.712932  ...  2.217286  4.895699      0        3\n",
              "4 -1.543432 -4.854725  1.101187  0.297339  ...  1.648459  6.916369      0        4\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTAMOGolFUm0",
        "colab_type": "text"
      },
      "source": [
        "In the next cell we generate target and target features. Note that we have separated cadre prediction features from target prediction features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAm3OTSD-ggD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# assign attributes\n",
        "t_cadres = 5\n",
        "t_samples = int(c_samples/t_cadres)\n",
        "t_features = 5\n",
        "t_classes = 2\n",
        "t_informative = 5\n",
        "t_seed = 101\n",
        "t_red = 0\n",
        "t_classep = 6\n",
        "t_flip = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0o2QGH2-gjU",
        "colab_type": "code",
        "outputId": "ae4da0ff-2b78-4115-8ae8-1f86a6b4ee74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df_variables = DGenerator.generate_variables(cadres = t_cadres, samples = t_samples, features = t_features, classes = t_classes, informative = t_informative, seed = t_seed, redundant = t_red, classep = t_classep, flip = t_flip)\n",
        "df_variables.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dv0</th>\n",
              "      <th>dv1</th>\n",
              "      <th>dv2</th>\n",
              "      <th>dv3</th>\n",
              "      <th>dv4</th>\n",
              "      <th>target</th>\n",
              "      <th>cadre</th>\n",
              "      <th>index_c</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.784785</td>\n",
              "      <td>6.177201</td>\n",
              "      <td>-5.189262</td>\n",
              "      <td>6.070376</td>\n",
              "      <td>-5.898889</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-7.783252</td>\n",
              "      <td>-5.636362</td>\n",
              "      <td>5.250647</td>\n",
              "      <td>5.624133</td>\n",
              "      <td>-6.060853</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-6.179748</td>\n",
              "      <td>-5.222403</td>\n",
              "      <td>-4.925779</td>\n",
              "      <td>6.182969</td>\n",
              "      <td>-6.919294</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7.143124</td>\n",
              "      <td>5.980376</td>\n",
              "      <td>-5.985737</td>\n",
              "      <td>6.742185</td>\n",
              "      <td>-5.723161</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.798002</td>\n",
              "      <td>7.331110</td>\n",
              "      <td>-6.460732</td>\n",
              "      <td>6.288602</td>\n",
              "      <td>-5.742962</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        dv0       dv1       dv2       dv3       dv4  target  cadre  index_c\n",
              "0  5.784785  6.177201 -5.189262  6.070376 -5.898889       1      0        0\n",
              "1 -7.783252 -5.636362  5.250647  5.624133 -6.060853       0      0        1\n",
              "2 -6.179748 -5.222403 -4.925779  6.182969 -6.919294       1      0        2\n",
              "3  7.143124  5.980376 -5.985737  6.742185 -5.723161       1      0        3\n",
              "4  4.798002  7.331110 -6.460732  6.288602 -5.742962       1      0        4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrRpy9a8-gpX",
        "colab_type": "code",
        "outputId": "2dbacd5c-3558-4539-9373-ce2703b59a2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# merge the two dataframes created\n",
        "z = pd.merge(df_cadre, df_variables)\n",
        "z.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cad0</th>\n",
              "      <th>cad1</th>\n",
              "      <th>cad2</th>\n",
              "      <th>cad3</th>\n",
              "      <th>cad4</th>\n",
              "      <th>cad5</th>\n",
              "      <th>cad6</th>\n",
              "      <th>cad7</th>\n",
              "      <th>cad8</th>\n",
              "      <th>cad9</th>\n",
              "      <th>cadre</th>\n",
              "      <th>index_c</th>\n",
              "      <th>dv0</th>\n",
              "      <th>dv1</th>\n",
              "      <th>dv2</th>\n",
              "      <th>dv3</th>\n",
              "      <th>dv4</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-4.482410</td>\n",
              "      <td>-4.619843</td>\n",
              "      <td>-0.997349</td>\n",
              "      <td>0.566676</td>\n",
              "      <td>2.126565</td>\n",
              "      <td>1.777562</td>\n",
              "      <td>3.996400</td>\n",
              "      <td>0.529722</td>\n",
              "      <td>5.346935</td>\n",
              "      <td>2.831843</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5.784785</td>\n",
              "      <td>6.177201</td>\n",
              "      <td>-5.189262</td>\n",
              "      <td>6.070376</td>\n",
              "      <td>-5.898889</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.477593</td>\n",
              "      <td>-3.269475</td>\n",
              "      <td>-0.234938</td>\n",
              "      <td>-0.763632</td>\n",
              "      <td>-0.596139</td>\n",
              "      <td>0.075753</td>\n",
              "      <td>6.446434</td>\n",
              "      <td>0.518770</td>\n",
              "      <td>5.242586</td>\n",
              "      <td>-4.823776</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5.784785</td>\n",
              "      <td>6.177201</td>\n",
              "      <td>-5.189262</td>\n",
              "      <td>6.070376</td>\n",
              "      <td>-5.898889</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-4.275286</td>\n",
              "      <td>-2.881474</td>\n",
              "      <td>-2.370080</td>\n",
              "      <td>-0.983635</td>\n",
              "      <td>0.938040</td>\n",
              "      <td>0.678835</td>\n",
              "      <td>3.397562</td>\n",
              "      <td>0.145567</td>\n",
              "      <td>3.981830</td>\n",
              "      <td>3.362928</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-7.783252</td>\n",
              "      <td>-5.636362</td>\n",
              "      <td>5.250647</td>\n",
              "      <td>5.624133</td>\n",
              "      <td>-6.060853</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.775304</td>\n",
              "      <td>-2.224774</td>\n",
              "      <td>-1.369726</td>\n",
              "      <td>-0.906824</td>\n",
              "      <td>-0.686132</td>\n",
              "      <td>0.601892</td>\n",
              "      <td>4.045526</td>\n",
              "      <td>1.985196</td>\n",
              "      <td>3.116355</td>\n",
              "      <td>-3.835390</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>-6.179748</td>\n",
              "      <td>-5.222403</td>\n",
              "      <td>-4.925779</td>\n",
              "      <td>6.182969</td>\n",
              "      <td>-6.919294</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-3.144241</td>\n",
              "      <td>-3.155927</td>\n",
              "      <td>-0.103750</td>\n",
              "      <td>0.712932</td>\n",
              "      <td>1.052544</td>\n",
              "      <td>0.615533</td>\n",
              "      <td>3.637596</td>\n",
              "      <td>-0.801713</td>\n",
              "      <td>2.217286</td>\n",
              "      <td>4.895699</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>7.143124</td>\n",
              "      <td>5.980376</td>\n",
              "      <td>-5.985737</td>\n",
              "      <td>6.742185</td>\n",
              "      <td>-5.723161</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       cad0      cad1      cad2      cad3  ...       dv2       dv3       dv4  target\n",
              "0 -4.482410 -4.619843 -0.997349  0.566676  ... -5.189262  6.070376 -5.898889       1\n",
              "1  1.477593 -3.269475 -0.234938 -0.763632  ... -5.189262  6.070376 -5.898889       1\n",
              "2 -4.275286 -2.881474 -2.370080 -0.983635  ...  5.250647  5.624133 -6.060853       0\n",
              "3  2.775304 -2.224774 -1.369726 -0.906824  ... -4.925779  6.182969 -6.919294       1\n",
              "4 -3.144241 -3.155927 -0.103750  0.712932  ... -5.985737  6.742185 -5.723161       1\n",
              "\n",
              "[5 rows x 18 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKvjJl7APsOH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_bin = z.drop(['index_c','cadre','target'], 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFnAytTLQH6G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bcolumns = df_bin.keys()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyO-Q53UQIEJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_binary = DGenerator.convert_binary(df_bin, bcolumns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBqGcNRHQIHp",
        "colab_type": "code",
        "outputId": "30e4f57d-f0ef-4bb1-ed0f-59810321c342",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df_binary.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cad0</th>\n",
              "      <th>cad1</th>\n",
              "      <th>cad2</th>\n",
              "      <th>cad3</th>\n",
              "      <th>cad4</th>\n",
              "      <th>cad5</th>\n",
              "      <th>cad6</th>\n",
              "      <th>cad7</th>\n",
              "      <th>cad8</th>\n",
              "      <th>cad9</th>\n",
              "      <th>dv0</th>\n",
              "      <th>dv1</th>\n",
              "      <th>dv2</th>\n",
              "      <th>dv3</th>\n",
              "      <th>dv4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   cad0  cad1  cad2  cad3  cad4  cad5  ...  cad9  dv0  dv1  dv2  dv3  dv4\n",
              "0     0     0     0     1     1     1  ...     1    1    1    0    1    0\n",
              "1     1     0     0     0     0     1  ...     0    1    1    0    1    0\n",
              "2     0     0     0     0     1     1  ...     1    0    0    1    1    0\n",
              "3     1     0     0     0     0     1  ...     0    0    0    0    1    0\n",
              "4     0     0     0     1     1     1  ...     1    1    1    0    1    0\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jx-itPTaGJMA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8abLi1JwLBUc",
        "colab_type": "code",
        "outputId": "0b7579f6-0d92-4d2f-9f20-ed81a2ce6a44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "\"\"\"\n",
        "for downloading dataframes\n",
        "from google.colab import files\n",
        "\n",
        "df_easy = z.drop(['index_c'], 1)\n",
        "df_easy.to_csv('df_easy.csv')\n",
        "files.download('df_easy.csv')\n",
        "\"\"\""
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nfor downloading dataframes\\nfrom google.colab import files\\n\\ndf_easy = z.drop(['index_c'], 1)\\ndf_easy.to_csv('df_easy.csv')\\nfiles.download('df_easy.csv')\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GGwy0T4xvNm",
        "colab_type": "text"
      },
      "source": [
        "# Begin KMeans Clustering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zmji6h8HxoNv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prep dataframe for kmeans\n",
        "from sklearn.cluster import KMeans\n",
        "df = z.drop(['cadre','index_c', 'target'], 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "025iNJNMx2_K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sum_sq = {}\n",
        "for k in range(1,40):\n",
        "    kmeans = KMeans(n_clusters = k).fit(df_binary)\n",
        "    sum_sq[k] = kmeans.inertia_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pBnfwJjx3Wx",
        "colab_type": "code",
        "outputId": "51345c4a-c38a-4d45-dec9-0cdefe229af3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "source": [
        "# plot elbow graph\n",
        "plt.plot(list(sum_sq.keys()),\n",
        "         list(sum_sq.values()),\n",
        "        linestyle = '-',\n",
        "        marker = 'H',\n",
        "        markersize = 2,\n",
        "        markerfacecolor = 'red')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fbd431661d0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nnaEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8l7uGuJyqY0",
        "colab_type": "text"
      },
      "source": [
        "From the figure above, we see that the optimum number of clusters goes beyond 30 which could have implications for analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQ_sMY1ByTLc",
        "colab_type": "code",
        "outputId": "69462638-df9c-4b76-b2c7-b76c29c0ebf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Append clusters to dataframe\n",
        "kmeans = KMeans(n_clusters = 10)\n",
        "kmeans.fit(df_binary)\n",
        "df_binary[\"kmeans\"] = kmeans.labels_\n",
        "df_binary.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cad0</th>\n",
              "      <th>cad1</th>\n",
              "      <th>cad2</th>\n",
              "      <th>cad3</th>\n",
              "      <th>cad4</th>\n",
              "      <th>cad5</th>\n",
              "      <th>cad6</th>\n",
              "      <th>cad7</th>\n",
              "      <th>cad8</th>\n",
              "      <th>cad9</th>\n",
              "      <th>dv0</th>\n",
              "      <th>dv1</th>\n",
              "      <th>dv2</th>\n",
              "      <th>dv3</th>\n",
              "      <th>dv4</th>\n",
              "      <th>kmeans</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   cad0  cad1  cad2  cad3  cad4  cad5  ...  dv0  dv1  dv2  dv3  dv4  kmeans\n",
              "0     0     0     0     1     1     1  ...    1    1    0    1    0       8\n",
              "1     1     0     0     0     0     1  ...    1    1    0    1    0       8\n",
              "2     0     0     0     0     1     1  ...    0    0    1    1    0       3\n",
              "3     1     0     0     0     0     1  ...    0    0    0    1    0       7\n",
              "4     0     0     0     1     1     1  ...    1    1    0    1    0       8\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYUM48EjTUVj",
        "colab_type": "code",
        "outputId": "7f6b364a-57ff-457a-978a-a51e2ccf1b41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df_binary[\"target\"] = z['target']\n",
        "df_binary.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cad0</th>\n",
              "      <th>cad1</th>\n",
              "      <th>cad2</th>\n",
              "      <th>cad3</th>\n",
              "      <th>cad4</th>\n",
              "      <th>cad5</th>\n",
              "      <th>cad6</th>\n",
              "      <th>cad7</th>\n",
              "      <th>cad8</th>\n",
              "      <th>cad9</th>\n",
              "      <th>dv0</th>\n",
              "      <th>dv1</th>\n",
              "      <th>dv2</th>\n",
              "      <th>dv3</th>\n",
              "      <th>dv4</th>\n",
              "      <th>kmeans</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   cad0  cad1  cad2  cad3  cad4  cad5  ...  dv1  dv2  dv3  dv4  kmeans  target\n",
              "0     0     0     0     1     1     1  ...    1    0    1    0       8       1\n",
              "1     1     0     0     0     0     1  ...    1    0    1    0       8       1\n",
              "2     0     0     0     0     1     1  ...    0    1    1    0       3       0\n",
              "3     1     0     0     0     0     1  ...    0    0    1    0       7       1\n",
              "4     0     0     0     1     1     1  ...    1    0    1    0       8       1\n",
              "\n",
              "[5 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suKCoKJJzWAC",
        "colab_type": "code",
        "outputId": "dba26062-a41b-479b-854b-aea84c3185af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# also we need to append kmeans clusters to dataframe z\n",
        "z[\"kmeans\"] = kmeans.labels_\n",
        "z.head()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cad0</th>\n",
              "      <th>cad1</th>\n",
              "      <th>cad2</th>\n",
              "      <th>cad3</th>\n",
              "      <th>cad4</th>\n",
              "      <th>cad5</th>\n",
              "      <th>cad6</th>\n",
              "      <th>cad7</th>\n",
              "      <th>cad8</th>\n",
              "      <th>cad9</th>\n",
              "      <th>cadre</th>\n",
              "      <th>index_c</th>\n",
              "      <th>dv0</th>\n",
              "      <th>dv1</th>\n",
              "      <th>dv2</th>\n",
              "      <th>dv3</th>\n",
              "      <th>dv4</th>\n",
              "      <th>target</th>\n",
              "      <th>kmeans</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-4.482410</td>\n",
              "      <td>-4.619843</td>\n",
              "      <td>-0.997349</td>\n",
              "      <td>0.566676</td>\n",
              "      <td>2.126565</td>\n",
              "      <td>1.777562</td>\n",
              "      <td>3.996400</td>\n",
              "      <td>0.529722</td>\n",
              "      <td>5.346935</td>\n",
              "      <td>2.831843</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5.784785</td>\n",
              "      <td>6.177201</td>\n",
              "      <td>-5.189262</td>\n",
              "      <td>6.070376</td>\n",
              "      <td>-5.898889</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.477593</td>\n",
              "      <td>-3.269475</td>\n",
              "      <td>-0.234938</td>\n",
              "      <td>-0.763632</td>\n",
              "      <td>-0.596139</td>\n",
              "      <td>0.075753</td>\n",
              "      <td>6.446434</td>\n",
              "      <td>0.518770</td>\n",
              "      <td>5.242586</td>\n",
              "      <td>-4.823776</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5.784785</td>\n",
              "      <td>6.177201</td>\n",
              "      <td>-5.189262</td>\n",
              "      <td>6.070376</td>\n",
              "      <td>-5.898889</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-4.275286</td>\n",
              "      <td>-2.881474</td>\n",
              "      <td>-2.370080</td>\n",
              "      <td>-0.983635</td>\n",
              "      <td>0.938040</td>\n",
              "      <td>0.678835</td>\n",
              "      <td>3.397562</td>\n",
              "      <td>0.145567</td>\n",
              "      <td>3.981830</td>\n",
              "      <td>3.362928</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-7.783252</td>\n",
              "      <td>-5.636362</td>\n",
              "      <td>5.250647</td>\n",
              "      <td>5.624133</td>\n",
              "      <td>-6.060853</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.775304</td>\n",
              "      <td>-2.224774</td>\n",
              "      <td>-1.369726</td>\n",
              "      <td>-0.906824</td>\n",
              "      <td>-0.686132</td>\n",
              "      <td>0.601892</td>\n",
              "      <td>4.045526</td>\n",
              "      <td>1.985196</td>\n",
              "      <td>3.116355</td>\n",
              "      <td>-3.835390</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>-6.179748</td>\n",
              "      <td>-5.222403</td>\n",
              "      <td>-4.925779</td>\n",
              "      <td>6.182969</td>\n",
              "      <td>-6.919294</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-3.144241</td>\n",
              "      <td>-3.155927</td>\n",
              "      <td>-0.103750</td>\n",
              "      <td>0.712932</td>\n",
              "      <td>1.052544</td>\n",
              "      <td>0.615533</td>\n",
              "      <td>3.637596</td>\n",
              "      <td>-0.801713</td>\n",
              "      <td>2.217286</td>\n",
              "      <td>4.895699</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>7.143124</td>\n",
              "      <td>5.980376</td>\n",
              "      <td>-5.985737</td>\n",
              "      <td>6.742185</td>\n",
              "      <td>-5.723161</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       cad0      cad1      cad2      cad3  ...       dv3       dv4  target  kmeans\n",
              "0 -4.482410 -4.619843 -0.997349  0.566676  ...  6.070376 -5.898889       1       8\n",
              "1  1.477593 -3.269475 -0.234938 -0.763632  ...  6.070376 -5.898889       1       8\n",
              "2 -4.275286 -2.881474 -2.370080 -0.983635  ...  5.624133 -6.060853       0       3\n",
              "3  2.775304 -2.224774 -1.369726 -0.906824  ...  6.182969 -6.919294       1       7\n",
              "4 -3.144241 -3.155927 -0.103750  0.712932  ...  6.742185 -5.723161       1       8\n",
              "\n",
              "[5 rows x 19 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okq7AgtNGG3f",
        "colab_type": "text"
      },
      "source": [
        "# Regular Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XU1GvYYMGL3M",
        "colab_type": "text"
      },
      "source": [
        "Now, we test a cadre-based regression to determine the accuracy of the logit regression tool. This will help us compare results with other tools later on"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2u3SVtk-gse",
        "colab_type": "code",
        "outputId": "12dd7172-ce86-410c-d184-7e9aa61bc486",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# import Logistic Regression Module\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "lr = LogisticRegression()\n",
        "\n",
        "#Test Cadre\n",
        "kmeans = 10\n",
        "for k in range(kmeans):\n",
        "\n",
        "    y_cadre = df_binary['target']\n",
        "    print(\"regression for cadre \", k)\n",
        "\n",
        "    # Drop row/observation from dataset if cadre == t\n",
        "    cadre = df_binary[df_binary.kmeans == k] \n",
        "\n",
        "    # Select X features for cadre t\n",
        "    X_cadre = cadre.drop(['target', 'kmeans'], axis=1) \n",
        "    print (X_cadre.shape)\n",
        "    # Select y features for cadre t\n",
        "    y_cadre = cadre['target'] \n",
        "   \n",
        "\n",
        "    # Run logistic regression\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_cadre, y_cadre, test_size=0.2, random_state=101)\n",
        "    \n",
        "    # check to see if target column has only one unique value(ie. 0 and 1)\n",
        "    if len(y_train.unique()) == 1:\n",
        "      print (\"all one class\")\n",
        "    \n",
        "    elif len(y_test.unique()) == 1:\n",
        "      print (\"all one class\")\n",
        "    \n",
        "    # ignore if target column has only one unique value(ie. 0 and 1)\n",
        "    else:\n",
        "      fit = lr.fit(X_train, y_train)\n",
        "\n",
        "      #test accuracy of predictions\n",
        "      y_train_pred = fit.predict(X_train)\n",
        "      y_test_pred = fit.predict(X_test)\n",
        "      \n",
        "      print(\"cadre\", k, \"train\", classification_report(y_train, y_train_pred))\n",
        "      print(classification_report(y_test, y_test_pred))\n",
        "      print (X_train.shape)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "regression for cadre  0\n",
            "(147, 15)\n",
            "all one class\n",
            "regression for cadre  1\n",
            "(146, 15)\n",
            "all one class\n",
            "regression for cadre  2\n",
            "(50, 15)\n",
            "cadre 2 train               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        15\n",
            "           1       1.00      1.00      1.00        25\n",
            "\n",
            "    accuracy                           1.00        40\n",
            "   macro avg       1.00      1.00      1.00        40\n",
            "weighted avg       1.00      1.00      1.00        40\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         3\n",
            "           1       1.00      1.00      1.00         7\n",
            "\n",
            "    accuracy                           1.00        10\n",
            "   macro avg       1.00      1.00      1.00        10\n",
            "weighted avg       1.00      1.00      1.00        10\n",
            "\n",
            "(40, 15)\n",
            "regression for cadre  3\n",
            "(60, 15)\n",
            "cadre 3 train               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        32\n",
            "           1       1.00      1.00      1.00        16\n",
            "\n",
            "    accuracy                           1.00        48\n",
            "   macro avg       1.00      1.00      1.00        48\n",
            "weighted avg       1.00      1.00      1.00        48\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         9\n",
            "           1       1.00      1.00      1.00         3\n",
            "\n",
            "    accuracy                           1.00        12\n",
            "   macro avg       1.00      1.00      1.00        12\n",
            "weighted avg       1.00      1.00      1.00        12\n",
            "\n",
            "(48, 15)\n",
            "regression for cadre  4\n",
            "(100, 15)\n",
            "cadre 4 train               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.97      0.97        36\n",
            "           1       0.98      0.98      0.98        44\n",
            "\n",
            "    accuracy                           0.97        80\n",
            "   macro avg       0.97      0.97      0.97        80\n",
            "weighted avg       0.97      0.97      0.97        80\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        14\n",
            "           1       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           1.00        20\n",
            "   macro avg       1.00      1.00      1.00        20\n",
            "weighted avg       1.00      1.00      1.00        20\n",
            "\n",
            "(80, 15)\n",
            "regression for cadre  5\n",
            "(103, 15)\n",
            "cadre 5 train               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99        42\n",
            "           1       0.98      1.00      0.99        40\n",
            "\n",
            "    accuracy                           0.99        82\n",
            "   macro avg       0.99      0.99      0.99        82\n",
            "weighted avg       0.99      0.99      0.99        82\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        11\n",
            "           1       1.00      1.00      1.00        10\n",
            "\n",
            "    accuracy                           1.00        21\n",
            "   macro avg       1.00      1.00      1.00        21\n",
            "weighted avg       1.00      1.00      1.00        21\n",
            "\n",
            "(82, 15)\n",
            "regression for cadre  6\n",
            "(79, 15)\n",
            "cadre 6 train               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.96      0.98        24\n",
            "           1       0.97      1.00      0.99        39\n",
            "\n",
            "    accuracy                           0.98        63\n",
            "   macro avg       0.99      0.98      0.98        63\n",
            "weighted avg       0.98      0.98      0.98        63\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         6\n",
            "           1       1.00      1.00      1.00        10\n",
            "\n",
            "    accuracy                           1.00        16\n",
            "   macro avg       1.00      1.00      1.00        16\n",
            "weighted avg       1.00      1.00      1.00        16\n",
            "\n",
            "(63, 15)\n",
            "regression for cadre  7\n",
            "(90, 15)\n",
            "cadre 7 train               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        48\n",
            "           1       1.00      1.00      1.00        24\n",
            "\n",
            "    accuracy                           1.00        72\n",
            "   macro avg       1.00      1.00      1.00        72\n",
            "weighted avg       1.00      1.00      1.00        72\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        11\n",
            "           1       1.00      1.00      1.00         7\n",
            "\n",
            "    accuracy                           1.00        18\n",
            "   macro avg       1.00      1.00      1.00        18\n",
            "weighted avg       1.00      1.00      1.00        18\n",
            "\n",
            "(72, 15)\n",
            "regression for cadre  8\n",
            "(101, 15)\n",
            "cadre 8 train               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.97      0.99        40\n",
            "           1       0.98      1.00      0.99        40\n",
            "\n",
            "    accuracy                           0.99        80\n",
            "   macro avg       0.99      0.99      0.99        80\n",
            "weighted avg       0.99      0.99      0.99        80\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       1.00      1.00      1.00        11\n",
            "\n",
            "    accuracy                           1.00        21\n",
            "   macro avg       1.00      1.00      1.00        21\n",
            "weighted avg       1.00      1.00      1.00        21\n",
            "\n",
            "(80, 15)\n",
            "regression for cadre  9\n",
            "(124, 15)\n",
            "cadre 9 train               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99        41\n",
            "           1       0.98      1.00      0.99        58\n",
            "\n",
            "    accuracy                           0.99        99\n",
            "   macro avg       0.99      0.99      0.99        99\n",
            "weighted avg       0.99      0.99      0.99        99\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.91      0.95        11\n",
            "           1       0.93      1.00      0.97        14\n",
            "\n",
            "    accuracy                           0.96        25\n",
            "   macro avg       0.97      0.95      0.96        25\n",
            "weighted avg       0.96      0.96      0.96        25\n",
            "\n",
            "(99, 15)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TeKRVt2KGuYb",
        "colab_type": "text"
      },
      "source": [
        "In the above cell, we find that accuracy is about 100%. This is not surprising because we manipulated the data to give us this result. The \"make_classification\" module used in the \"DGen.py\" file helped us to do this. In the next cell, we test the same regression model on the entire dataset irrespective of cadres"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIKcbWl7HhBQ",
        "colab_type": "code",
        "outputId": "de3ea9c5-ebbe-4d3b-fa9c-821e22e1db7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        }
      },
      "source": [
        "data = df_binary.drop(['kmeans'], 1)\n",
        "\n",
        "X = data.drop(['target'], 1)\n",
        "y = data['target']\n",
        "\n",
        "# Run logistic regression\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)\n",
        "result = lr.fit(X_train, y_train)\n",
        "\n",
        "pred = result.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, pred))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.70      0.76       111\n",
            "           1       0.69      0.81      0.74        89\n",
            "\n",
            "    accuracy                           0.75       200\n",
            "   macro avg       0.75      0.76      0.75       200\n",
            "weighted avg       0.76      0.75      0.75       200\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LK_m4424H-4c",
        "colab_type": "text"
      },
      "source": [
        "In the above cell, regression irrespective of cadres gives us an accuracy of about 75%. This is expected because we anticipate the cadre-based regression to perform better."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4_rRppFsj_Z",
        "colab_type": "code",
        "outputId": "f8fb6626-fc9d-440f-d230-684dac26467d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        }
      },
      "source": [
        "z.groupby('cadre').describe()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"8\" halign=\"left\">cad0</th>\n",
              "      <th colspan=\"8\" halign=\"left\">cad1</th>\n",
              "      <th colspan=\"8\" halign=\"left\">cad2</th>\n",
              "      <th colspan=\"8\" halign=\"left\">cad3</th>\n",
              "      <th colspan=\"8\" halign=\"left\">cad4</th>\n",
              "      <th>...</th>\n",
              "      <th colspan=\"8\" halign=\"left\">dv2</th>\n",
              "      <th colspan=\"8\" halign=\"left\">dv3</th>\n",
              "      <th colspan=\"8\" halign=\"left\">dv4</th>\n",
              "      <th colspan=\"8\" halign=\"left\">target</th>\n",
              "      <th colspan=\"8\" halign=\"left\">kmeans</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "      <th>...</th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cadre</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>201.0</td>\n",
              "      <td>-0.031299</td>\n",
              "      <td>4.298202</td>\n",
              "      <td>-7.058527</td>\n",
              "      <td>-4.183709</td>\n",
              "      <td>0.491360</td>\n",
              "      <td>3.898695</td>\n",
              "      <td>8.494276</td>\n",
              "      <td>201.0</td>\n",
              "      <td>-3.858840</td>\n",
              "      <td>1.451228</td>\n",
              "      <td>-7.989711</td>\n",
              "      <td>-4.824086</td>\n",
              "      <td>-3.921019</td>\n",
              "      <td>-2.857948</td>\n",
              "      <td>0.627914</td>\n",
              "      <td>201.0</td>\n",
              "      <td>0.034784</td>\n",
              "      <td>0.997655</td>\n",
              "      <td>-3.292171</td>\n",
              "      <td>-0.624795</td>\n",
              "      <td>0.087221</td>\n",
              "      <td>0.665948</td>\n",
              "      <td>2.584190</td>\n",
              "      <td>201.0</td>\n",
              "      <td>0.000670</td>\n",
              "      <td>0.990043</td>\n",
              "      <td>-3.106611</td>\n",
              "      <td>-0.658003</td>\n",
              "      <td>-0.062796</td>\n",
              "      <td>0.652247</td>\n",
              "      <td>2.272282</td>\n",
              "      <td>201.0</td>\n",
              "      <td>-0.024353</td>\n",
              "      <td>0.980420</td>\n",
              "      <td>-2.751150</td>\n",
              "      <td>-0.706356</td>\n",
              "      <td>0.017328</td>\n",
              "      <td>0.666852</td>\n",
              "      <td>2.746184</td>\n",
              "      <td>...</td>\n",
              "      <td>201.0</td>\n",
              "      <td>-0.102252</td>\n",
              "      <td>6.154557</td>\n",
              "      <td>-9.350291</td>\n",
              "      <td>-6.112103</td>\n",
              "      <td>-2.543719</td>\n",
              "      <td>5.937811</td>\n",
              "      <td>8.699651</td>\n",
              "      <td>201.0</td>\n",
              "      <td>6.040185</td>\n",
              "      <td>1.500807</td>\n",
              "      <td>1.757147</td>\n",
              "      <td>5.089443</td>\n",
              "      <td>5.887543</td>\n",
              "      <td>6.949020</td>\n",
              "      <td>10.394675</td>\n",
              "      <td>201.0</td>\n",
              "      <td>-2.992275</td>\n",
              "      <td>5.310469</td>\n",
              "      <td>-10.536961</td>\n",
              "      <td>-6.455622</td>\n",
              "      <td>-5.510090</td>\n",
              "      <td>-2.387424</td>\n",
              "      <td>7.414602</td>\n",
              "      <td>201.0</td>\n",
              "      <td>0.502488</td>\n",
              "      <td>0.501242</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>201.0</td>\n",
              "      <td>6.089552</td>\n",
              "      <td>2.040083</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.00</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.00</td>\n",
              "      <td>9.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>201.0</td>\n",
              "      <td>0.130477</td>\n",
              "      <td>4.431900</td>\n",
              "      <td>-7.108085</td>\n",
              "      <td>-4.203660</td>\n",
              "      <td>0.439350</td>\n",
              "      <td>4.253706</td>\n",
              "      <td>7.132228</td>\n",
              "      <td>201.0</td>\n",
              "      <td>0.073604</td>\n",
              "      <td>4.141082</td>\n",
              "      <td>-6.142546</td>\n",
              "      <td>-3.694247</td>\n",
              "      <td>-1.224814</td>\n",
              "      <td>3.973181</td>\n",
              "      <td>8.577598</td>\n",
              "      <td>201.0</td>\n",
              "      <td>-0.042276</td>\n",
              "      <td>1.079199</td>\n",
              "      <td>-2.352243</td>\n",
              "      <td>-0.974315</td>\n",
              "      <td>-0.119941</td>\n",
              "      <td>0.668155</td>\n",
              "      <td>2.889061</td>\n",
              "      <td>201.0</td>\n",
              "      <td>0.081829</td>\n",
              "      <td>0.926848</td>\n",
              "      <td>-2.243721</td>\n",
              "      <td>-0.544237</td>\n",
              "      <td>0.031784</td>\n",
              "      <td>0.716706</td>\n",
              "      <td>2.535838</td>\n",
              "      <td>201.0</td>\n",
              "      <td>-0.059765</td>\n",
              "      <td>1.041017</td>\n",
              "      <td>-2.868137</td>\n",
              "      <td>-0.814925</td>\n",
              "      <td>0.020655</td>\n",
              "      <td>0.675735</td>\n",
              "      <td>3.062575</td>\n",
              "      <td>...</td>\n",
              "      <td>201.0</td>\n",
              "      <td>2.997189</td>\n",
              "      <td>5.268094</td>\n",
              "      <td>-8.240974</td>\n",
              "      <td>2.386563</td>\n",
              "      <td>5.459082</td>\n",
              "      <td>6.334774</td>\n",
              "      <td>9.266384</td>\n",
              "      <td>201.0</td>\n",
              "      <td>2.951976</td>\n",
              "      <td>5.384295</td>\n",
              "      <td>-9.290466</td>\n",
              "      <td>2.881044</td>\n",
              "      <td>5.540473</td>\n",
              "      <td>6.339882</td>\n",
              "      <td>10.127601</td>\n",
              "      <td>201.0</td>\n",
              "      <td>3.002152</td>\n",
              "      <td>5.523055</td>\n",
              "      <td>-10.134666</td>\n",
              "      <td>2.621049</td>\n",
              "      <td>5.612523</td>\n",
              "      <td>6.428694</td>\n",
              "      <td>9.244459</td>\n",
              "      <td>201.0</td>\n",
              "      <td>0.502488</td>\n",
              "      <td>0.501242</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>201.0</td>\n",
              "      <td>7.616915</td>\n",
              "      <td>1.355549</td>\n",
              "      <td>3.0</td>\n",
              "      <td>6.00</td>\n",
              "      <td>8.0</td>\n",
              "      <td>9.00</td>\n",
              "      <td>9.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>200.0</td>\n",
              "      <td>-0.069676</td>\n",
              "      <td>4.194419</td>\n",
              "      <td>-6.521632</td>\n",
              "      <td>-4.208975</td>\n",
              "      <td>0.107642</td>\n",
              "      <td>4.009701</td>\n",
              "      <td>5.896408</td>\n",
              "      <td>200.0</td>\n",
              "      <td>4.011029</td>\n",
              "      <td>1.304587</td>\n",
              "      <td>-0.211852</td>\n",
              "      <td>3.214323</td>\n",
              "      <td>3.938816</td>\n",
              "      <td>4.841970</td>\n",
              "      <td>7.707968</td>\n",
              "      <td>200.0</td>\n",
              "      <td>-0.118307</td>\n",
              "      <td>0.966572</td>\n",
              "      <td>-2.922648</td>\n",
              "      <td>-0.678636</td>\n",
              "      <td>-0.086218</td>\n",
              "      <td>0.551891</td>\n",
              "      <td>2.128296</td>\n",
              "      <td>200.0</td>\n",
              "      <td>0.003276</td>\n",
              "      <td>0.971193</td>\n",
              "      <td>-2.657049</td>\n",
              "      <td>-0.569243</td>\n",
              "      <td>0.058888</td>\n",
              "      <td>0.563402</td>\n",
              "      <td>3.243386</td>\n",
              "      <td>200.0</td>\n",
              "      <td>0.085653</td>\n",
              "      <td>1.015121</td>\n",
              "      <td>-2.477027</td>\n",
              "      <td>-0.689462</td>\n",
              "      <td>0.079383</td>\n",
              "      <td>0.781516</td>\n",
              "      <td>2.640866</td>\n",
              "      <td>...</td>\n",
              "      <td>200.0</td>\n",
              "      <td>2.942896</td>\n",
              "      <td>5.399318</td>\n",
              "      <td>-9.744640</td>\n",
              "      <td>1.282649</td>\n",
              "      <td>5.269171</td>\n",
              "      <td>6.555523</td>\n",
              "      <td>10.705268</td>\n",
              "      <td>200.0</td>\n",
              "      <td>-3.165729</td>\n",
              "      <td>5.325886</td>\n",
              "      <td>-9.234960</td>\n",
              "      <td>-6.735534</td>\n",
              "      <td>-5.475266</td>\n",
              "      <td>-1.879450</td>\n",
              "      <td>9.939947</td>\n",
              "      <td>200.0</td>\n",
              "      <td>-0.099918</td>\n",
              "      <td>6.145492</td>\n",
              "      <td>-9.201958</td>\n",
              "      <td>-6.099983</td>\n",
              "      <td>-0.275715</td>\n",
              "      <td>5.930753</td>\n",
              "      <td>9.042249</td>\n",
              "      <td>200.0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.501255</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>200.0</td>\n",
              "      <td>5.205000</td>\n",
              "      <td>2.452150</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.25</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.25</td>\n",
              "      <td>9.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>200.0</td>\n",
              "      <td>-4.019848</td>\n",
              "      <td>0.856367</td>\n",
              "      <td>-6.615413</td>\n",
              "      <td>-4.588261</td>\n",
              "      <td>-4.008422</td>\n",
              "      <td>-3.430812</td>\n",
              "      <td>-1.854720</td>\n",
              "      <td>200.0</td>\n",
              "      <td>4.080630</td>\n",
              "      <td>1.664083</td>\n",
              "      <td>-2.306741</td>\n",
              "      <td>3.243691</td>\n",
              "      <td>4.118640</td>\n",
              "      <td>5.044105</td>\n",
              "      <td>9.936877</td>\n",
              "      <td>200.0</td>\n",
              "      <td>0.086875</td>\n",
              "      <td>1.088292</td>\n",
              "      <td>-3.403847</td>\n",
              "      <td>-0.690503</td>\n",
              "      <td>0.110415</td>\n",
              "      <td>0.827008</td>\n",
              "      <td>3.243187</td>\n",
              "      <td>200.0</td>\n",
              "      <td>-0.057101</td>\n",
              "      <td>1.046517</td>\n",
              "      <td>-3.117099</td>\n",
              "      <td>-0.858211</td>\n",
              "      <td>-0.018991</td>\n",
              "      <td>0.641591</td>\n",
              "      <td>2.606300</td>\n",
              "      <td>200.0</td>\n",
              "      <td>0.143117</td>\n",
              "      <td>0.965498</td>\n",
              "      <td>-2.443601</td>\n",
              "      <td>-0.382067</td>\n",
              "      <td>0.188280</td>\n",
              "      <td>0.857387</td>\n",
              "      <td>4.155123</td>\n",
              "      <td>...</td>\n",
              "      <td>200.0</td>\n",
              "      <td>-3.063994</td>\n",
              "      <td>5.330468</td>\n",
              "      <td>-8.904473</td>\n",
              "      <td>-6.469041</td>\n",
              "      <td>-5.625080</td>\n",
              "      <td>-1.137071</td>\n",
              "      <td>7.998358</td>\n",
              "      <td>200.0</td>\n",
              "      <td>2.877973</td>\n",
              "      <td>5.540661</td>\n",
              "      <td>-10.511058</td>\n",
              "      <td>0.655365</td>\n",
              "      <td>5.533329</td>\n",
              "      <td>6.411644</td>\n",
              "      <td>11.188928</td>\n",
              "      <td>200.0</td>\n",
              "      <td>-2.893704</td>\n",
              "      <td>5.385458</td>\n",
              "      <td>-10.041080</td>\n",
              "      <td>-6.338250</td>\n",
              "      <td>-5.533643</td>\n",
              "      <td>-0.628974</td>\n",
              "      <td>8.250206</td>\n",
              "      <td>200.0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.501255</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>200.0</td>\n",
              "      <td>1.330000</td>\n",
              "      <td>1.713411</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.00</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>198.0</td>\n",
              "      <td>-0.081689</td>\n",
              "      <td>4.224734</td>\n",
              "      <td>-6.446648</td>\n",
              "      <td>-4.197512</td>\n",
              "      <td>-0.104985</td>\n",
              "      <td>4.100377</td>\n",
              "      <td>7.308801</td>\n",
              "      <td>198.0</td>\n",
              "      <td>-4.011986</td>\n",
              "      <td>1.271893</td>\n",
              "      <td>-7.147353</td>\n",
              "      <td>-4.741817</td>\n",
              "      <td>-3.982761</td>\n",
              "      <td>-3.074444</td>\n",
              "      <td>-1.138555</td>\n",
              "      <td>198.0</td>\n",
              "      <td>-0.016548</td>\n",
              "      <td>1.086553</td>\n",
              "      <td>-3.388461</td>\n",
              "      <td>-0.704474</td>\n",
              "      <td>-0.107396</td>\n",
              "      <td>0.729247</td>\n",
              "      <td>2.622554</td>\n",
              "      <td>198.0</td>\n",
              "      <td>0.124097</td>\n",
              "      <td>1.027026</td>\n",
              "      <td>-2.534433</td>\n",
              "      <td>-0.432731</td>\n",
              "      <td>-0.023205</td>\n",
              "      <td>0.786861</td>\n",
              "      <td>3.959325</td>\n",
              "      <td>198.0</td>\n",
              "      <td>0.071578</td>\n",
              "      <td>1.023852</td>\n",
              "      <td>-2.405368</td>\n",
              "      <td>-0.649629</td>\n",
              "      <td>0.076924</td>\n",
              "      <td>0.769165</td>\n",
              "      <td>3.142104</td>\n",
              "      <td>...</td>\n",
              "      <td>198.0</td>\n",
              "      <td>0.092160</td>\n",
              "      <td>6.185626</td>\n",
              "      <td>-8.231905</td>\n",
              "      <td>-6.061937</td>\n",
              "      <td>-0.027459</td>\n",
              "      <td>6.225587</td>\n",
              "      <td>8.525399</td>\n",
              "      <td>198.0</td>\n",
              "      <td>2.983763</td>\n",
              "      <td>5.451616</td>\n",
              "      <td>-9.113360</td>\n",
              "      <td>2.474017</td>\n",
              "      <td>5.411117</td>\n",
              "      <td>6.560026</td>\n",
              "      <td>12.465974</td>\n",
              "      <td>198.0</td>\n",
              "      <td>0.121139</td>\n",
              "      <td>6.040670</td>\n",
              "      <td>-7.602992</td>\n",
              "      <td>-5.855442</td>\n",
              "      <td>0.371061</td>\n",
              "      <td>6.139582</td>\n",
              "      <td>8.431471</td>\n",
              "      <td>198.0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.501267</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>198.0</td>\n",
              "      <td>1.550505</td>\n",
              "      <td>1.559310</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.00</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 144 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        cad0                                          ... kmeans                      \n",
              "       count      mean       std       min       25%  ...    min   25%  50%   75%  max\n",
              "cadre                                                 ...                             \n",
              "0      201.0 -0.031299  4.298202 -7.058527 -4.183709  ...    3.0  3.00  7.0  8.00  9.0\n",
              "1      201.0  0.130477  4.431900 -7.108085 -4.203660  ...    3.0  6.00  8.0  9.00  9.0\n",
              "2      200.0 -0.069676  4.194419 -6.521632 -4.208975  ...    2.0  4.25  5.0  5.25  9.0\n",
              "3      200.0 -4.019848  0.856367 -6.615413 -4.588261  ...    0.0  0.00  1.0  4.00  5.0\n",
              "4      198.0 -0.081689  4.224734 -6.446648 -4.197512  ...    0.0  1.00  1.0  4.00  6.0\n",
              "\n",
              "[5 rows x 144 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dviaOwQOHODH",
        "colab_type": "text"
      },
      "source": [
        "# Begin SCM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGz8qwCGHRnT",
        "colab_type": "text"
      },
      "source": [
        "Next, we replicate the work done so far on SCM with help from Alex, Xiao and George's codes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXg0ITQzJZe2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# SCM import\n",
        "sys.path.append('supervised-cadres/cadreModels')\n",
        "from classificationBinary import binaryCadreModel\n",
        "from classificationMulti import multilabelCadreModel"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lt2brwdS-gvX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# randomized train-test-split\n",
        "Dtr, Dva = train_test_split(data, test_size=0.2, random_state=101)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_arP8s2-gyS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Identify cadre prediction features from target prediction features (optional)\n",
        "cadreFts = data.columns[data.columns.str.contains('cad')]\n",
        "predictFts = data.columns[data.columns.str.contains('dv')]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BvAGpk2-g1W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# merge features\n",
        "features = cadreFts.union(predictFts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIIYjiSH-g4L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# standardize training and validation sets\n",
        "Dva[features] = zmap(Dva[features].values, Dtr[features].values)\n",
        "Dtr[features] = zscore(Dtr[features].values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jukP2l01I4KI",
        "colab_type": "text"
      },
      "source": [
        "Alex notes:\n",
        "\n",
        "Define and train SCM model object. We're not going to tune any hyperparameters here. Note that we now supply the binaryCadreModel object with the cadre-assignment features and target-prediction features, as well as the name of the target feature.\n",
        "\n",
        "If we did not supply any cadreFts or targetFts, they default to being every column in data other than targetCol"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFvYdOTX-g7n",
        "colab_type": "code",
        "outputId": "f9cb519a-42a8-4d9b-b617-de336355656f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        }
      },
      "source": [
        "# Xiao: just has to tune the parameters.\n",
        "\n",
        "scm = binaryCadreModel(M=10,lambda_d=0.001,lambda_W=0.001, Tmax=7001, record=500,gamma=1,eta=2e-2)\n",
        "scm.fit(data=Dtr,\n",
        "       targetCol='target',\n",
        "       cadreFts=cadreFts,\n",
        "       predictFts=predictFts,\n",
        "       dataVa=Dva,\n",
        "       progress=True)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0709 03:39:54.422424 140451748226944 deprecation_wrapper.py:119] From supervised-cadres/cadreModels/classificationBinary.py:114: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n",
            "W0709 03:39:54.470195 140451748226944 deprecation_wrapper.py:119] From supervised-cadres/cadreModels/classificationBinary.py:141: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0709 03:39:54.596567 140451748226944 deprecation_wrapper.py:119] From supervised-cadres/cadreModels/classificationBinary.py:168: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0709 03:39:54.626926 140451748226944 deprecation_wrapper.py:119] From supervised-cadres/cadreModels/classificationBinary.py:182: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "W0709 03:39:54.706771 140451748226944 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0709 03:39:55.014601 140451748226944 deprecation_wrapper.py:119] From supervised-cadres/cadreModels/classificationBinary.py:185: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "W0709 03:39:55.040120 140451748226944 deprecation_wrapper.py:119] From supervised-cadres/cadreModels/classificationBinary.py:191: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "numbers being printed: SGD iteration, training loss, training accuracy, validation loss, validation accuracy, time\n",
            "0\n",
            "500 0.7255065 0.3875 0.72089124 0.435 1.094135046005249\n",
            "1000 0.33845192 0.945 0.32913458 0.93 35.06263589859009\n",
            "training has terminated because: lack of sufficient decrease in validation ROC_AUC\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<classificationBinary.binaryCadreModel at 0x7fbd1ebb00b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CvILsZHKBCr",
        "colab_type": "text"
      },
      "source": [
        "Alex notes:\n",
        "\n",
        "The metrics attribute of scm contains training and validation metrics values. We can plot them separately. ROC_AUC is the receiver operator characteristic area under the curve (sklearn.metrics.roc_auc_score). PR_AUC is the average precision, i.e., area under the precision-recall curve (sklearn.metrics.average_precision_score).\n",
        "\n",
        "The x-axis in these plots are dependent on iteration count."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CfMRBja-g-c",
        "colab_type": "code",
        "outputId": "d3d53f83-23fd-4abc-a4c2-65b057bafe61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "source": [
        "scm.metrics['training'].plot()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fbd1ebb0128>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD8CAYAAACfF6SlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgcUquwb-hBr",
        "colab_type": "code",
        "outputId": "b3dce320-ed73-49ac-c1c5-503dbd898853",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "source": [
        "scm.metrics['validation'].plot()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fbd1016cf28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD8CAYAAACfF6SlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_GgTSLimIca",
        "colab_type": "text"
      },
      "source": [
        "We can use the `predictFull` method for the `binaryCadreModel` class to calculate a variety of quantities on a new dataset. In the below chunk:\n",
        "\n",
        "- `margin` -- classification margin scores\n",
        "- `label` -- predicted labels\n",
        "- `cadre_weight` -- a matrix of cadre membership probabilities\n",
        "- `cadre` -- predicted cadre memberships\n",
        "- `loss` -- loss value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tFXsv-6-hIW",
        "colab_type": "code",
        "outputId": "6b012402-6dc0-4ebb-ddf2-9ba58ee9cd99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "scm.scoreMetrics(Dva)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>ROC_AUC</th>\n",
              "      <th>PR_AUC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.253037</td>\n",
              "      <td>0.995</td>\n",
              "      <td>0.99838</td>\n",
              "      <td>0.997814</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       loss  accuracy  ROC_AUC    PR_AUC\n",
              "0  0.253037     0.995  0.99838  0.997814"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxJ1aWOSKuha",
        "colab_type": "code",
        "outputId": "145eb22d-c0a9-400b-e2e2-10791c40ae14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "scm.entropy(Dtr)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.31797561,  0.04549924, -0.        ,  0.22237923,  1.28485756,\n",
              "        0.14204216,  0.38271828, -0.        ,  0.09554176,  0.10231049])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzdgzJwGJrhi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f, l, G, m, l = scm.predictFull(Dva)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38EZQcSVNjTS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from itertools import product\n",
        "from joblib import Parallel, delayed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmYQDI6_Njat",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def scmCrossval(d_tr, d_va, d_te, M, l_W, l_d, cadre_fts, predict_fts, Tmax, record):\n",
        "    mod = binaryCadreModel(\n",
        "                Tmax=Tmax, record=record,\n",
        "                M=M, alpha_d=0.99, alpha_W=0.99, lambda_d=l_d, lambda_W=l_W, gamma=1.)\n",
        "        \n",
        "    mod.fit(d_tr, 'target', cadre_fts, predict_fts, d_va, progress=False)\n",
        "    \n",
        "    ## evaluate on validation and test sets\n",
        "    err_va = mod.scoreMetrics(d_va)\n",
        "    err_te = mod.scoreMetrics(d_te)\n",
        "    \n",
        "    ## return everything as a list\n",
        "    return mod, err_va, err_te"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xh2jWHu9Njev",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import KFold"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mN6Mip8GNjh1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l_ds = np.array([0.01, 0.001])\n",
        "l_Ws = np.array([0.01, 0.001])\n",
        "Ms = np.array([4,6,8,10])\n",
        "n_folds = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSL1pFMKNjk_",
        "colab_type": "code",
        "outputId": "b84113bc-d1b9-43c1-e4b8-b2b1ff83a2ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        }
      },
      "source": [
        "kf = KFold(n_splits=n_folds, random_state=1414)\n",
        "\n",
        "n_jobs = np.minimum(12, n_folds * Ms.shape[0] * l_ds.shape[0] * l_Ws.shape[0])\n",
        "\n",
        "results = (Parallel(n_jobs=n_jobs, backend='threading', verbose=11)(delayed(scmCrossval)\n",
        "                    (Dtr.iloc[tr], Dtr.iloc[va], Dva, M, l_W, l_d, features, features, 20001, 1000) \n",
        "                    for (M, l_d, l_W, (fold, (tr, va))) in product(Ms, l_ds, l_Ws, enumerate(kf.split(Dtr)))))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
            "[Parallel(n_jobs=12)]: Done   1 tasks      | elapsed: 220.8min\n",
            "[Parallel(n_jobs=12)]: Done   2 tasks      | elapsed: 264.9min\n",
            "[Parallel(n_jobs=12)]: Done   3 tasks      | elapsed: 284.9min\n",
            "[Parallel(n_jobs=12)]: Done   4 tasks      | elapsed: 322.5min\n",
            "[Parallel(n_jobs=12)]: Done   5 tasks      | elapsed: 338.1min\n",
            "[Parallel(n_jobs=12)]: Done   6 tasks      | elapsed: 354.9min\n",
            "[Parallel(n_jobs=12)]: Done   7 tasks      | elapsed: 380.6min\n",
            "[Parallel(n_jobs=12)]: Done   8 tasks      | elapsed: 392.6min\n",
            "[Parallel(n_jobs=12)]: Done   9 tasks      | elapsed: 413.5min\n",
            "[Parallel(n_jobs=12)]: Done  10 tasks      | elapsed: 413.8min\n",
            "[Parallel(n_jobs=12)]: Done  11 tasks      | elapsed: 414.0min\n",
            "[Parallel(n_jobs=12)]: Done  12 tasks      | elapsed: 414.5min\n",
            "[Parallel(n_jobs=12)]: Done  13 tasks      | elapsed: 414.5min\n",
            "[Parallel(n_jobs=12)]: Done  14 tasks      | elapsed: 414.7min\n",
            "[Parallel(n_jobs=12)]: Done  15 tasks      | elapsed: 475.2min\n",
            "[Parallel(n_jobs=12)]: Done  16 tasks      | elapsed: 475.3min\n",
            "[Parallel(n_jobs=12)]: Done  17 tasks      | elapsed: 495.6min\n",
            "[Parallel(n_jobs=12)]: Done  18 tasks      | elapsed: 516.4min\n",
            "[Parallel(n_jobs=12)]: Done  19 tasks      | elapsed: 526.5min\n",
            "[Parallel(n_jobs=12)]: Done  20 tasks      | elapsed: 536.7min\n",
            "[Parallel(n_jobs=12)]: Done  21 tasks      | elapsed: 537.3min\n",
            "[Parallel(n_jobs=12)]: Done  22 tasks      | elapsed: 537.7min\n",
            "[Parallel(n_jobs=12)]: Done  23 tasks      | elapsed: 547.7min\n",
            "[Parallel(n_jobs=12)]: Done  24 tasks      | elapsed: 578.2min\n",
            "[Parallel(n_jobs=12)]: Done  25 tasks      | elapsed: 589.5min\n",
            "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed: 609.8min\n",
            "[Parallel(n_jobs=12)]: Done  27 tasks      | elapsed: 619.0min\n",
            "[Parallel(n_jobs=12)]: Done  28 tasks      | elapsed: 620.6min\n",
            "[Parallel(n_jobs=12)]: Done  29 tasks      | elapsed: 651.1min\n",
            "[Parallel(n_jobs=12)]: Done  30 tasks      | elapsed: 671.7min\n",
            "[Parallel(n_jobs=12)]: Done  31 tasks      | elapsed: 672.4min\n",
            "[Parallel(n_jobs=12)]: Done  32 tasks      | elapsed: 672.5min\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ipjTIulNjoI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_scores(results):\n",
        "    results_va, results_te = [], []\n",
        "    for model, scores_va, scores_te in results:\n",
        "        results_va.append(scores_va)\n",
        "        results_va[-1] = results_va[-1].assign(M=model.M, lambda_d=model.lambda_d, lambda_W=model.lambda_W)\n",
        "        \n",
        "        results_te.append(scores_te)\n",
        "        results_te[-1] = results_te[-1].assign(M=model.M, lambda_d=model.lambda_d, lambda_W=model.lambda_W)\n",
        "    results_va = pd.concat(results_va).reset_index(drop=True)\n",
        "    results_te = pd.concat(results_te).reset_index(drop=True)\n",
        "    print(results_va.head())\n",
        "    print(results_te.head())\n",
        "    return results_va, results_te"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4nmIEe8NjrW",
        "colab_type": "code",
        "outputId": "23b1c7d0-44a5-4f09-cb3d-40a4e34da02a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        }
      },
      "source": [
        "scores_va, scores_te = extract_scores(results)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-fe395fe7016b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscores_va\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores_te\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErQS-e7zNju6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_best_attributes(scores):\n",
        "    group = scores.groupby(['M','lambda_d','lambda_W'])\n",
        "    return group.mean().reset_index().sort_values('ROC_AUC', ascending=False).head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cTE7CNAQli7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "get_best_attributes(scores_va)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVWJP90eQlmd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_scores(results):\n",
        "    results_va, results_te = [], []\n",
        "    for model, scores_va, scores_te in results:\n",
        "        results_va.append(scores_va)\n",
        "        results_va[-1] = results_va[-1].assign(M=model.M, lambda_d=model.lambda_d, lambda_W=model.lambda_W)\n",
        "        \n",
        "        results_te.append(scores_te)\n",
        "        results_te[-1] = results_te[-1].assign(M=model.M, lambda_d=model.lambda_d, lambda_W=model.lambda_W)\n",
        "    results_va = pd.concat(results_va).reset_index(drop=True)\n",
        "    results_te = pd.concat(results_te).reset_index(drop=True)\n",
        "    print(results_va.head())\n",
        "    print(results_te.head())\n",
        "    return results_va, results_te"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-NhJpswQls7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scores_va, scores_te = extract_scores(results)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKqXtlG5Qlv0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_best_attributes(scores):\n",
        "    group = scores.groupby(['M','lambda_d','lambda_W'])\n",
        "    return group.mean().reset_index().sort_values('ROC_AUC', ascending=False).head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipOOWhutQlyU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "get_best_attributes(scores_va)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xsfbQWTQl32",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scm_best = binaryCadreModel(Tmax=20001, record=1000, eps=1e-4, lambda_W=0.001, lambda_d=0.001, M=10, gamma=1.)\n",
        "scm_best.fit(Dtr, 'target', features, features, Dva, progress=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Frh260uvw7km",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scm.scoreMetrics(Dva)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGrraDO9Ql66",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scm_best.scoreMetrics(Dva)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCI8im37Ql1Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import roc_auc_score, average_precision_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QF2Anz3TxAFl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def precision_metrics(data, model, data_name, M):\n",
        "    F, L, __, M, __ = model.predictFull(data)\n",
        "    temp = pd.DataFrame({'f': np.squeeze(F), 'm': np.squeeze(M), 'l': np.squeeze(L), 'y': data['target'].values})\n",
        "    scores = {'size': [], 'm': [], 'dataset': [], 'accuracy': [], 'ROC_AUC': [], 'PR_AUC': [], 'proportion': []}\n",
        "    for m in np.unique(M):\n",
        "        temp_m = temp.loc[temp['m']==m,:]\n",
        "        if temp_m.shape[0] < 5: continue\n",
        "        scores['size'].append(temp_m.shape[0])\n",
        "        scores['m'].append(m)\n",
        "        scores['dataset'].append(data_name)\n",
        "        scores['proportion'].append(temp_m['y'].mean())\n",
        "        scores['accuracy'].append(np.mean(temp_m['l'] == temp_m['y']))\n",
        "        scores['ROC_AUC'].append(roc_auc_score(temp_m['y'], temp_m['f']))\n",
        "        scores['PR_AUC'].append(average_precision_score(temp_m['y'], temp_m['f']))\n",
        "    return pd.DataFrame(scores)[['dataset', 'm', 'size', 'proportion', 'accuracy', 'ROC_AUC', 'PR_AUC']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AMaejvZxAI4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "precision_metrics(Dva, scm_best, 'synthetic', 6)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MCgqysdxAL1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ocn1dvbxAPn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHsPs1uaxASg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQYyBQdHQlqA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWHUYh35NjyJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMJVxDNKNj08",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXEtxBcvJkaR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pd.Series(m).value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnAwLW4p-hE8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#margin, label, cadre_weight, cadre, loss = scm.predictFull(Dva)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJFNLcjZSrkO",
        "colab_type": "text"
      },
      "source": [
        "# Begin SGMM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTjEO_uUUvca",
        "colab_type": "text"
      },
      "source": [
        "In this section, we use the SGMM to perform a logistic regression focusing on cadre-based accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfN9r-SjKdDG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# SGMM import\n",
        "#sys.path.insert(0, '../notebooks')\n",
        "print(sys.path)\n",
        "from supervisedGmm import SupervisedGMM\n",
        "from metricsFunctions import calc_metrics, CalculateSoftLogReg, optimalTau,metrics_cluster\n",
        "from loaders2 import loader\n",
        "from mlModels import logisticRegressionCv2, neural_nets, randomforests,\\\n",
        "kmeansLogRegr, xboost, gradboost\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dURaEu7gTE3W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data1 = data.sample(frac=1,random_state=1512)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5c0Dxtd-PtB4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "columns = ['cluster', 'size', 'target_1','target_0', \n",
        "                       'TP', 'TN', 'FP', 'FN', \n",
        "                       'FPR', 'specificity', 'sensitivity', 'precision',\n",
        "                       'accuracy', 'balanced accuracy', 'f1', 'auc']\n",
        "features = list(data1.iloc[:,:-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxIKfHPzKdT9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed( seed = 0)\n",
        "n_clusters = 10\n",
        "alpha = [0.1, 0.2, 0.5, 1,5]\n",
        "model = SupervisedGMM( cv=10, alpha = alpha, n_clusters = n_clusters, max_iter = 50, max_iter2 = 5, adaR=1, transduction = 0)\n",
        "Xtrain, Xtest, ytrain, ytest = model.split( data = data1.values)\n",
        "model = model.fit( Xtrain = Xtrain, Xtest = [], ytrain = ytrain, simple = 0, kmeans = 1, mod = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Op1vEf69Kdc5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mTest, mTrain = model.mTest, model.mTrain\n",
        "logisRegre = model.LogRegr\n",
        "fitP = model.fitParams\n",
        "labTrain, labTest = fitP['labTrain'], fitP['labTest']\n",
        "\n",
        "probTest, probTrain = model.predict_prob_int( Xtest = Xtest, Xtrain = Xtrain )\n",
        "tau = optimalTau(probTrain, ytrain)\n",
        "metTest,_ = calc_metrics(custom_prob = probTest.copy(), tau = tau, y = ytest)\n",
        "metTrain ,_= calc_metrics(custom_prob = probTrain.copy(), tau = tau, y = ytrain)\n",
        "metTestSGMM = pd.DataFrame( [metTest], columns = columns)\n",
        "metTrainSGMM = pd.DataFrame( [metTrain], columns = columns)\n",
        "print(metTestSGMM, metTrainSGMM)\n",
        "print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVtN11tXVZIo",
        "colab_type": "text"
      },
      "source": [
        "For the training set above, we find that accuracy is about 100% for all cadres. Similar to results from the SCM section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cO1Ns0kAWOH4",
        "colab_type": "text"
      },
      "source": [
        "# Logit Reg with Additional Classification Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AG7agLTmJbue",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Note:\n",
        "high_cost represents \"target == 1\" and\n",
        "low_cost represents \"target == 0\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvkVHQnm-hRH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Cs = [1,10,100,1000]\n",
        "#FITTING L1 LOGISTIC REGRESSION\n",
        "pL1, probTestL1, probTrainL1 = logisticRegressionCv2( Xtrain = Xtrain,\n",
        "                                                  ytrain = ytrain,\n",
        "                                                  Xtest = Xtest,\n",
        "                                                  ytest = ytest, Cs = Cs )\n",
        "tau = optimalTau(probTrainL1, ytrain)\n",
        "\n",
        "metTest,_ = calc_metrics(custom_prob = probTestL1.copy(), tau = tau, y = ytest)\n",
        "metTrain ,_= calc_metrics(custom_prob = probTrainL1.copy(), tau = tau, y = ytrain)\n",
        "metTestL1 = pd.DataFrame( [metTest], columns = columns)\n",
        "metTrainL1 = pd.DataFrame( [metTrain], columns = columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_Y0NZpq-hUH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Fitting Neural Nets\n",
        "pNN, probTestNN, probTrainNN = neural_nets( Xtrain = Xtrain,\n",
        "                                                  ytrain = ytrain,\n",
        "                                                  Xtest = Xtest,\n",
        "                                                  ytest = ytest,\n",
        "                                                  h_l_s = (4 ,4, 2))\n",
        "tau = optimalTau(probTrainNN, ytrain)\n",
        "\n",
        "metTest,_ = calc_metrics(custom_prob = probTestNN.copy(), tau = tau, y = ytest)\n",
        "metTrain ,_= calc_metrics(custom_prob = probTrainNN.copy(), tau = tau, y = ytrain)\n",
        "metTestNN = pd.DataFrame( [metTest], columns = columns)\n",
        "metTrainNN = pd.DataFrame( [metTrain], columns = columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tl6BiqVb-hZy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#RANDOM FORESTS\n",
        "params, probTest, probTrain = randomforests(Xtrain = Xtrain, ytrain = ytrain,\n",
        "                                            Xtest = Xtest, ytest = ytest)\n",
        "\n",
        "tau = optimalTau(probTrain, ytrain)\n",
        "metTest,_ = calc_metrics(custom_prob = probTest.copy(), tau = tau, y = ytest)\n",
        "metTrain ,_= calc_metrics(custom_prob = probTrain.copy(), tau = tau, y = ytrain)\n",
        "\n",
        "#PANDA MATRICES\n",
        "metTestRF = pd.DataFrame( [metTest], columns = columns)\n",
        "metTrainRF = pd.DataFrame( [metTrain], columns = columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFn5B1BW-hgI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Ada boost\n",
        "params, probTest, probTrain = xboost(Xtrain = Xtrain, ytrain = ytrain,\n",
        "                                            Xtest = Xtest, ytest = ytest)\n",
        "\n",
        "tau = optimalTau(probTrain, ytrain)\n",
        "metTest,_ = calc_metrics(custom_prob = probTest.copy(), tau = tau, y = ytest)\n",
        "metTrain ,_= calc_metrics(custom_prob = probTrain.copy(), tau = tau, y = ytrain)\n",
        "\n",
        "#PANDA MATRICES\n",
        "metTestXB = pd.DataFrame( [metTest], columns = columns)\n",
        "metTrainXB = pd.DataFrame( [metTrain], columns = columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToYcCDaU-hdQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Grad boost\n",
        "params, probTest, probTrain = gradboost(Xtrain = Xtrain, ytrain = ytrain,\n",
        "                                            Xtest = Xtest, ytest = ytest)\n",
        "\n",
        "tau = optimalTau(probTrain, ytrain)\n",
        "metTest,_ = calc_metrics(custom_prob = probTest.copy(), tau = tau, y = ytest)\n",
        "metTrain ,_= calc_metrics(custom_prob = probTrain.copy(), tau = tau, y = ytrain)\n",
        "\n",
        "#PANDA MATRICES\n",
        "metTestGB = pd.DataFrame( [metTest], columns = columns)\n",
        "metTrainGB = pd.DataFrame( [metTrain], columns = columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wd_0W02IQgfa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JD5ipGXlW39N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCTtc_HSW4Es",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainmet = pd.concat([metTrainL1,metTrainSGMM,metTrainRF,metTrainNN,metTrainXB,metTrainGB],ignore_index=True)\n",
        "testmet = pd.concat([metTestL1,metTestSGMM,metTestRF,metTestNN,metTestXB,metTestGB],ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ids9ZuqW4Id",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "method = ['L1 Reg','SGMM','RF','NN','AdaBoost','GradBoost']\n",
        "trainmet.insert(8,'method',method)\n",
        "testmet.insert(8,'method',method)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPe4khiTW4B0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainmet.iloc[:,8:].round(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOLmqUTPW35d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testmet.iloc[:,8:].round(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1CX0jjwW32Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scm.scoreMetrics(Dva)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOWZ_aqdIkK4",
        "colab_type": "text"
      },
      "source": [
        "Future / Related Tasks:\n",
        "We made the clusters easily identifiable by tuning the make_classification function. \n",
        "For our next test dataset, we will make the clusters difficult to identify to help identify which models perform better"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0I3sDTw-gmv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUuVjoZA-gT_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}